{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:21:03.014817Z",
     "start_time": "2024-02-04T08:21:02.989567Z"
    }
   },
   "id": "645a76b7f58d849b",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from deepgd.model import *\n",
    "from deepgd.data import ScalableGraphData\n",
    "from deepgd.datasets import SuiteSparseDataset\n",
    "from deepgd.model_old import Stress"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:29:42.735443Z",
     "start_time": "2024-02-04T08:29:42.549071Z"
    }
   },
   "id": "5dce613f274a5c15",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn, jit\n",
    "import torch_geometric as pyg\n",
    "import torch_scatter\n",
    "from tqdm.auto import *\n",
    "from attrs import define, NOTHING"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:26:29.071287Z",
     "start_time": "2024-02-04T08:26:28.977939Z"
    }
   },
   "id": "2f4731bba24080bb",
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T08:28:10.130150Z",
     "start_time": "2024-02-04T08:28:09.996121Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "for backend, device_name in {\n",
    "    torch.backends.mps: \"mps\",\n",
    "    torch.cuda: \"cuda\",\n",
    "}.items():\n",
    "    if backend.is_available():\n",
    "        device = device_name"
   ],
   "id": "4ca18f24ca543add",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(\n",
    "    params=NOTHING,\n",
    "    block_config=NOTHING,\n",
    "    edge_net_config=NOTHING,\n",
    "    gnn_config=NOTHING,\n",
    "    edge_feat_expansion=NOTHING,\n",
    "    eps=NOTHING\n",
    ")\n",
    "generator = jit.script(generator)\n",
    "generator = torch.compile(generator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:57:09.340784Z",
     "start_time": "2024-02-04T08:57:02.625389Z"
    }
   },
   "id": "a95542165bdaa292",
   "execution_count": 34
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:21:21.455126Z",
     "start_time": "2024-02-04T08:21:21.240190Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "jit.save(generator, 'generator.pt')"
   ],
   "id": "a277282048e64c35",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = jit.load('generator.pt').to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T08:28:41.884707Z",
     "start_time": "2024-02-04T08:28:41.083725Z"
    }
   },
   "id": "aa733e4d5eb9f09e",
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T08:28:22.467635Z",
     "start_time": "2024-02-04T08:28:22.438979Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "lr = 0.001\n",
    "landmarks = 20\n",
    "rand_edges = 20\n",
    "batch_size = 1"
   ],
   "id": "cf231eb99f2a01dd",
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T08:25:04.266240Z",
     "start_time": "2024-02-04T08:25:04.207151Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574,\n",
       " tensor([162, 457,  79, 338, 478, 307, 156, 342, 167,  64, 127, 305, 138, 411,\n",
       "         521, 382, 467,  82, 181, 118,  80, 182, 423, 104, 293, 398, 119,   8,\n",
       "         140,  73, 361, 134, 391, 332, 566, 545, 531, 456, 431, 102, 269, 573,\n",
       "          90, 466, 369, 266, 330, 113, 267, 196, 229,   2, 201,  45, 537, 496,\n",
       "         328,  74, 325, 244, 387,  78, 170, 482, 281, 193, 542, 418, 285, 333,\n",
       "         321,  10, 406, 329,  14, 558,  88, 314, 356, 529, 344,   5, 427, 376,\n",
       "          31, 126, 383, 554, 108, 145, 535, 268, 351, 141, 505, 132, 180, 303,\n",
       "         327, 211, 200, 133, 380, 389,  12,  69,   7, 497, 438, 123, 473, 179,\n",
       "          34, 569, 386, 517, 448, 221, 403, 175, 352, 203, 253, 336, 164,  75,\n",
       "         508, 433, 347, 130,  38,  68, 514, 273, 270, 420, 262, 213,  43, 360,\n",
       "         107, 568, 250, 353, 552, 161, 384, 417,  52, 275, 414,  89, 358, 135,\n",
       "         248, 543, 177, 442, 254, 192, 154, 546, 272,  28, 477, 373, 488, 235,\n",
       "         219, 409, 189, 304, 337,  26, 238, 355, 495,  44, 447, 451, 190, 289,\n",
       "         455, 220,  59, 539, 498, 506,  94, 379, 111, 232, 392,  18, 339, 359,\n",
       "          29, 413, 507, 551, 286, 483, 484, 500, 207, 288, 245, 349, 242, 205,\n",
       "         136, 109, 226, 532, 208, 194, 494, 282, 297, 424, 152, 147,  60,  48,\n",
       "          53, 157, 524, 298, 279, 105, 503, 504, 306,  55,   0,  20, 308, 116,\n",
       "         144, 255, 290, 334,  50,   9, 469, 223, 148, 449, 520, 367, 103, 263,\n",
       "         492, 343, 172, 230, 341, 129, 480, 168, 284,   1,  62, 128, 571, 435,\n",
       "         474, 428, 271, 142, 261, 555,  54, 295,  92,  99, 541, 415, 240, 432,\n",
       "         390,  42, 150,  47, 231, 311, 101, 374, 472, 426, 395, 425,  61, 354,\n",
       "          70,  87, 131, 485, 257, 287, 453,   6, 185, 533, 362, 394, 570, 335,\n",
       "         550, 510, 252, 302, 198, 197, 396, 346,  36,  40, 459, 292, 371, 322,\n",
       "         416, 375, 209, 445, 222, 475, 210, 562, 400, 110, 218, 567, 236, 283,\n",
       "          21, 125, 258, 300,  85, 301, 318, 153, 280, 399, 313, 444, 233, 249,\n",
       "         471, 151,  71, 441, 491, 121, 408, 214, 486, 247, 155, 112, 345, 163,\n",
       "          63,  30, 188,  11, 393, 470, 499,  37, 176,  86, 525, 186, 557, 165,\n",
       "          23, 430, 299, 227, 512,  51,  81,  84, 357, 402, 511, 452,  19, 340,\n",
       "         309,  58,  49, 276,  46, 513, 159,  32, 139, 378, 436, 324, 274, 549,\n",
       "         316, 149,  97,  27, 239, 319, 443, 246, 439, 106, 120, 437, 264, 225,\n",
       "          56, 509, 115, 171, 178, 479, 366, 259,  96, 405, 183, 385, 528, 199,\n",
       "         481, 143, 217, 326, 114, 169, 404,  98, 538,  22, 117,  35, 422, 216,\n",
       "         501, 160, 544, 368, 317,  67, 527,  24, 241, 410, 412, 323, 372, 277,\n",
       "         519, 572, 191, 518, 202, 522, 278, 184, 365,  16, 421, 536, 315, 419,\n",
       "         100, 166, 228,  39, 493, 256, 462, 440, 556, 463, 265, 215, 534, 548,\n",
       "         350,  17, 158, 450, 137, 397, 429, 516, 407, 291, 526, 237,  72, 559,\n",
       "         146, 487, 224, 565,  33, 523, 174, 234, 173, 296, 388, 312,   4, 560,\n",
       "         195, 446,  13, 212, 461, 502, 490, 206,  76, 401,  65,   3, 364, 122,\n",
       "         381,  77, 331, 460,  15, 377, 434,  95, 251, 563, 243,  66,  91,  57,\n",
       "         564, 465, 458, 530, 547, 540, 204, 363, 320, 464, 468, 489, 348, 561,\n",
       "         515, 310, 476,  93, 294, 124, 553, 187, 454, 370,  41, 260,  83,  25]))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "torch.random.manual_seed(12345)\n",
    "dataset = SuiteSparseDataset(\n",
    "    min_nodes=0,\n",
    "    max_nodes=7500,\n",
    "    limit=1000,\n",
    "    datatype=ScalableGraphData,\n",
    "    datatype_args=dict(\n",
    "        device=device,\n",
    "        landmarks=20,\n",
    "        random_edges=20\n",
    "    )\n",
    ")\n",
    "shuffled_dataset, perm_idx = dataset.shuffle(return_perm=True)\n",
    "len(shuffled_dataset), perm_idx"
   ],
   "id": "4078b62ee74a974b",
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T08:25:05.409656Z",
     "start_time": "2024-02-04T08:25:05.375349Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loader = pyg.loader.DataLoader(shuffled_dataset[:550], batch_size=batch_size, shuffle=True)\n",
    "val_loader = pyg.loader.DataLoader(shuffled_dataset[550:], batch_size=batch_size, shuffle=False)"
   ],
   "id": "fc8740c7e57b2515",
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T08:29:47.556818Z",
     "start_time": "2024-02-04T08:29:47.522094Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "criteria = {\n",
    "    Stress(): 1,\n",
    "    # EdgeVar(): 0,\n",
    "    # Occlusion(): 0,\n",
    "    # IncidentAngle(): 0,\n",
    "    # TSNEScore(): 0,\n",
    "}"
   ],
   "id": "2d54eed126566eb2",
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T08:57:35.582781Z",
     "start_time": "2024-02-04T08:57:35.541490Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=lr)"
   ],
   "id": "aaebc077bfc8726d",
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T09:30:20.449021Z",
     "start_time": "2024-02-04T08:57:37.553453Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4639aa9389e04864a28edb73cf79fb5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "127c65dfd5544a10b226c76411f4906f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train Loss:\t86045.79\n",
      "[Epoch 0] Edge Ratio:\t0.15\n",
      "[Epoch 0] Val Loss:\t65711.33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8bc271aa6874fafa5295cc040ceae59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c, w \u001B[38;5;129;01min\u001B[39;00m criteria\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 10\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minit_pos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m w \u001B[38;5;241m*\u001B[39m c(pred, batch)\n\u001B[1;32m     12\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:328\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    326\u001B[0m dynamic_ctx\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__enter__\u001B[39m()\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 328\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     set_eval_frame(prior)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in trange(100):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    edge_ratios = []\n",
    "    for batch in tqdm(train_loader, disable=False):\n",
    "        batch = batch.to(device)\n",
    "        model.zero_grad()\n",
    "        loss = 0\n",
    "        for c, w in criteria.items():\n",
    "            pred = model(init_pos=batch.x, edge_index=batch.edge_index, edge_attr=batch.edge_attr, batch_index=batch.batch)\n",
    "            loss += w * c(pred, batch)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses.append(loss.item())\n",
    "        edge_ratios.append((batch.edge_attr.shape[0] / (batch.n * (batch.n - 1)).sum()).item())\n",
    "    print(f'[Epoch {epoch}] Train Loss:\\t{np.mean(losses):.2f}')\n",
    "    print(f'[Epoch {epoch}] Edge Ratio:\\t{np.mean(edge_ratios):.2f}')\n",
    "    with torch.no_grad():\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for batch in tqdm(val_loader, disable=True):\n",
    "            batch = batch.to(device)\n",
    "            loss = 0\n",
    "            for c, w in criteria.items():\n",
    "                pred = model(init_pos=batch.x, edge_index=batch.edge_index, edge_attr=batch.edge_attr, batch_index=batch.batch)\n",
    "                loss += w * c(pred, batch)\n",
    "            losses.append(loss.item())\n",
    "        print(f'[Epoch {epoch}] Val Loss:\\t{np.mean(losses):.2f}')\n",
    "    torch.save(model.state_dict(), \"model.ckpt\")"
   ],
   "id": "c99910d0c210870f",
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "f96a6f5e05e1a069",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
